# SuperResolution
DeepLearning programs for SuperResolution

## 3.2 スパースコーディング（SC）に基づく手法との関係性

SCに基づくSuper-Resolution（SR）法は、畳み込みニューラルネットワークとみることができる。

スパースコーディング手法では、まずf1xf1の低解像パッチが抽出される
→辞書サイズがn1の場合、入力画像にn1の線形フィルタ（f1xf1）を適用することと等価である
（平均を引くことは線形演算であるため、これに内包される）

SC手法は、n1の係数を繰り返し処理する。
この手法の出力はn2個の係数であり、通常、SCの場合n1=n2である

n2この係数はHighResolutuion(HR)パッチの表現である
そのため、SC手法は空間サポートが1x1の非線形演算の特別なケースとしてふるまう（Fig.3の中央）

しかし、SC手法はフィードフォワードではない（例えば繰り返しアルゴリズム）のに対して、我々の非線形演算はFullyフィードフォワードであり、効率的に演算できる
f2=1とすると、非線形演算はピクセルごとの全結合層とみることができる

SRCNNのSC手法は、最初の2つの層を指しており、第2層やReLUだけを指しているのではないということは注目に値する

このように、SRCNNの非線形演算は、学習プロセスを通して最適化される。

--
上述の(SC後の)n2係数は別の(HR)辞書に投影され、高解像パッチを生成する。

HRパッチがオーバーラップすることにより平均化される。
上述の議論より、n2特徴量マップ上の線形畳み込みと等価である。

再構成に利用されるHRパッチのサイズがf3xf3である場合、線形フィルタはf3xf3の空間サポートと等価である。（Fig.3の右）

--

上述の議論は、SR法に基づいたSC手法がある種の畳み込みニューラルネットワークであることを示している。
しかし、SR法に基づいてたSCにおける最適化において、すべての演算が考慮されているわけではない。

逆に、我々のCNNでは、低解像辞書、高解像辞書、非線形マッピング、平均減算と平均化が最適化されたフィルタにおいてすべて含まれている。

したがって我々のすべての操作を含んだend-to-endのマッピングを最適化する。

--

上記の解析は、ハイパーパラメータのデザインにも役立つ。
例えば、最後の層のフィルタサイズを最初の層のフィルタサイズよりも小さくすることができる。
つまり、高解像パッチの中心部分に依存することになる。
(f3=1なら、平均化されない中心画素を使用することとなる)

また、それぞれがより疎となることが期待されるためn2<n1とすることができる。

典型的で基本的な設定は
f1=9
f2=1
f3=5
n1=64
n2=32
とする。

全体として、高解像画素は、（9 + 5 - 1）^2 = 169画素を利用することとなる。

明らかに、再構成のために利用される情報は、
例えば、（5 + 5　-　1）^2 = 81ピクセルを使用する既存の外部の例に基づくアプローチで使用される情報よりも比較的大きい。

これにより、SRCNNがより高い性能を発揮する理由の一つである。
